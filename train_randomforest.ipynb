{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dir = 'data/features'\n",
    "#dir = 'data/features_sample'\n",
    "train = pd.read_pickle(os.path.join(dir, 'train.pkl'))\n",
    "valid = pd.read_pickle(os.path.join(dir, 'valid.pkl'))\n",
    "test = pd.read_pickle(os.path.join(dir, 'test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_in_use = [\n",
    "    'num_morphemes',\n",
    "    'negative',\n",
    "    'self_ref',\n",
    "    'cognitive',\n",
    "    'hedges',\n",
    "    'hesitations',\n",
    "    'exlusion_words',\n",
    "    'negations',\n",
    "    'motion_words',\n",
    "    'sense_words',\n",
    "    'noun',\n",
    "    'verb',\n",
    "    'particle',\n",
    "    'adjective',\n",
    "    'conjunction',\n",
    "    'connections',\n",
    "]\n",
    "\n",
    "def make_data(df, type='sum'):\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        _X, _y = _make_data(row, type=type)\n",
    "        X.append(_X)\n",
    "        y.append(_y)\n",
    "    return X, y\n",
    "\n",
    "def _make_data(row, type='sum'):\n",
    "    if type=='sum':\n",
    "        X = [row[f'{col}_sum'] for col in col_in_use]\n",
    "        X.append(row['TTR'])\n",
    "    elif type=='mean':\n",
    "        X = [row[f'{col}_mean'] for col in col_in_use]\n",
    "        X.append(row['TTR'])\n",
    "    elif type=='std':\n",
    "        X = [row[f'{col}_std'] for col in col_in_use]\n",
    "        X.append(row['TTR'])\n",
    "    elif type=='all':\n",
    "        X = [row[f'{col}_sum'] for col in col_in_use]\n",
    "        X.extend([row[f'{col}_mean'] for col in col_in_use])\n",
    "        X.extend([row[f'{col}_std'] for col in col_in_use])\n",
    "        X.append(row['TTR'])\n",
    "    y = row.labels\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "type='sum'\n",
    "train_X, train_y = make_data(train, type=type)\n",
    "valid_X, valid_y = make_data(valid, type=type)\n",
    "train_X.extend(valid_X), train_y.extend(valid_y)\n",
    "test_X, test_y = make_data(test, type=type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "forest = RandomForestClassifier(random_state=1).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5237704918032787\n",
      "      0    1\n",
      "0  5566  534\n",
      "1  5276  824\n",
      "\n",
      "   precision    recall        f1  support\n",
      "0   0.513374  0.912459  0.657065   6100.0\n",
      "1   0.606775  0.135082  0.220971   6100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "save_dir = ('outputs/nested/randomforest')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "predict = forest.predict(test_X)\n",
    "acc = accuracy_score(test_y, predict)\n",
    "c_report = classification_report(test_y, predict)\n",
    "cm = pd.DataFrame(confusion_matrix(test_y, predict))\n",
    "scores_df = pd.DataFrame(np.array(precision_recall_fscore_support(test_y, predict)).T,\n",
    "            columns=[\"precision\", \"recall\", \"f1\", \"support\"],\n",
    "        )\n",
    "\n",
    "print(acc)\n",
    "print(cm)\n",
    "print(c_report)\n",
    "print(scores_df)\n",
    "\n",
    "with open(os.path.join(save_dir, 'classification_report.txt'), 'w') as f:\n",
    "        f.write(str(acc)+'\\n')\n",
    "        f.write(c_report)\n",
    "cm.to_csv(os.path.join('cm.csv'))\n",
    "scores_df.to_csv(os.path.join(save_dir, 'scores.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fb0056378317a9ced497e21f9ad1030b78be77748927f9cf06c62d2ffd6c3d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
