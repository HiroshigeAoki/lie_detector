hydra:
  run:
    dir: outputs/${data.name}/${model.name}/${experiment}/${outputdir_name}

experiment: baseline
outputdir_name: ${now:%Y-%m-%d_%H%M%S}
message:
workplace_dir: /home/haoki/dev/lie_detector
checkpoint_dir: null #outputs以下の相対パス ex) nested/HAN/200_dim200_sp/checkpoints

defaults:
  - _self_
  - model: HAN
  - tokenizer: sentencepiece
  - data: nested
  - optim: AdamW

use_gmail_notification: false

mode: train
best_epoch: 0

# Pytorch lightning trainer's argument
# default flags are commented to avoid clustering the hyperparameters
trainer:
  # accelerator: None
  accelerator: "gpu"
  devices: [0]
  accumulate_grad_batches: 1
  benchmark: True
  deterministic: True
  fast_dev_run: False
  max_epochs: 10
  precision: 16

early_stopping:
  _target_ : pytorch_lightning.callbacks.EarlyStopping
  monitor: 'val_loss'
  min_delta: 0.005
  patience: 3
  mode: 'min'
  check_on_train_epoch_end: False

checkpoint_callback:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  filename: '{epoch}'
  monitor: 'val_loss'
  verbose: True
  save_top_k: 1
  mode: 'min'