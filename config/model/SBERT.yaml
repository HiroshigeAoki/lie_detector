name: SBERT

args:
  loss_fnct: 'semi_hard'
  word_embedding_model: ''
  batch_size: 64

fit:
  epochs: 1
  evaluation_steps: 1000
  use_amp: True
  steps_per_epoch: 0
  # scheduler: 'WarmupLinear'
  # optimizer_class: transformers.AdamW
  # optimizer_params: {'lr': 2e-5}
  # weight_decay: 0.01
  output_path: './'
  # save_best_model: True
  # max_grad_norm: 1
  # show_progress_bar: True
  checkpoint_path: 'checkpoints'
  checkpoint_save_steps: 1000
  checkpoint_save_total_limit: 2
  checkpoint_path_to_resume: None
  resume_training: False